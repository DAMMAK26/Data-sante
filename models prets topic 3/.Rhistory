# Liste des variables cibles # Performance scolaire
target_columns <- c('ss2',  # Comportements préventifs
'sante','tb1',   # Anxiété de santé
)
# Charger les bibliothèques nécessaires
library(tidymodels)
library(data.table)
library(readxl)
# Charger les données
data <- read_excel("dataset_complet2.xlsx")
df <- as.data.table(data)
df <- df[complete.cases(df), ]
# Liste des variables d'intérêt
columns_of_interest <- c(
'ss2',  # Comportements préventifs
'sante','tb1',   # Anxiété de santé
'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Filtrer le dataframe pour ne garder que les colonnes d'intérêt
df_filtered <- df[, ..columns_of_interest]
# Split dataset (Train/Test)
df_split <- initial_split(df_filtered, prop = 0.8)
train <- training(df_split)
test <- testing(df_split)
# Liste des variables cibles # Performance scolaire
target_columns <- c('ss2',  # Comportements préventifs
'sante','tb1'   # Anxiété de santé
)
# Liste des variables explicatives
predictor_columns <- c(    'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Fonction d'entraînement du modèle
train_reg_model <- function(target_column) {
# Convertir la variable cible en facteur
train[[target_column]] <- as.factor(train[[target_column]])
# Créer la formule du modèle
formula <- as.formula(paste(target_column, "~", paste(predictor_columns, collapse = " + ")))
# Créer le modèle de régression logistique multinomiale
log_reg <- multinom_reg() %>%
set_engine("nnet") %>%
set_mode("classification")
# Créer le workflow
log_reg_wf <- workflow() %>%
add_model(log_reg) %>%
add_formula(formula)
# Entraîner le modèle
trained_log_reg <- fit(log_reg_wf, data = train)
return(trained_log_reg)
}
get_preds_model <- function (model, target_column){
the_preds <-predict(model, new_data = test, type = "class")$.pred_class
return( the_preds)
}
# Fonction de test du modèle et calcul des métriques
test_model <- function(model, target_column) {
# Prédictions sur l'ensemble de test
the_preds <- predict(model, new_data = test)$.pred_class
# Convertir la variable cible en facteur et récupérer les prédictions
test[[target_column]] <- factor(test[[target_column]], levels = levels(the_preds))
# Calculer les métriques de performance
metrics <- metric_set(accuracy, precision, recall, f_meas)
# Créer un data frame avec les véritables valeurs et les prédictions
results_df <- tibble(
truth = test[[target_column]],
estimate = the_preds
)
# Calculer les métriques
the_metrics <- metrics(results_df, truth = truth, estimate = estimate)
return(the_metrics)
}
test_model_on_columns <- function(target_columns, used_model_funtcion){
# Appliquer les fonctions à toutes les variables cibles
results <- list()
preds <- list()
for (target_column in target_columns) {
# Entraîner le modèle pour chaque variable cible
trained_model <- used_model_funtcion(target_column)
preds[[target_column]] <- get_preds_model(trained_model ,target_column )
# Tester le modèle et récupérer les métriques
metrics <- test_model(trained_model, target_column)
# Ajouter les résultats au tableau
results[[target_column]] <- metrics
}
# Afficher les résultats
return(list(results = results, preds = preds))
}
# Utiliser la fonction avec un vecteur de colonnes cibles
resultats_et_predictions <- test_model_on_columns(target_columns,train_reg_model )
# Extraire les résultats et les prédictions
results <- resultats_et_predictions$results
preds <- resultats_et_predictions$preds
# Afficher les résultats et les prédictions
results
preds
# Charger les bibliothèques nécessaires
library(tidymodels)
library(data.table)
library(readxl)
# Charger les données
data <- read_excel("dataset_complet2.xlsx")
df <- as.data.table(data)
df <- df[complete.cases(df), ]
# Liste des variables d'intérêt
columns_of_interest <- c(
'ss2',  # Comportements préventifs
'sante','tb1',   # Anxiété de santé
'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Filtrer le dataframe pour ne garder que les colonnes d'intérêt
df_filtered <- df[, ..columns_of_interest]
# Split dataset (Train/Test)
df_split <- initial_split(df_filtered, prop = 0.8)
train <- training(df_split)
test <- testing(df_split)
# Liste des variables cibles # Performance scolaire
target_columns <- c('ss2',  # Comportements préventifs
'sante','tb1'   # Anxiété de santé
)
# Liste des variables explicatives
predictor_columns <- c(    'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Fonction d'entraînement du modèle
train_nb_model <- function(target_column) {
# Convertir les variables explicatives en numériques si nécessaire
train[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
test[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
# Convertir la variable cible en facteur dans l'ensemble d'entraînement et de test
train[[target_column]] <- as.factor(train[[target_column]])
test[[target_column]] <- as.factor(test[[target_column]])
# Assurez-vous que les niveaux dans l'ensemble de test sont les mêmes que ceux dans l'ensemble d'entraînement
test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
# Convertir la variable cible en facteur (car c'est une classification multiclasse)
train[[target_column]] <- as.factor(train[[target_column]])
# Créer la formule du modèle
formula <- as.formula(paste(target_column, "~", paste(predictor_columns, collapse = " + ")))
# Naive Bayes
nb <- naive_Bayes() %>% set_engine("klaR") %>% set_mode("classification")
nb_wf <- workflow() %>% add_model(nb) %>% add_formula(formula)
cv_folds <- vfold_cv(train, v = 5, strata = target_column)
nb_results <- tune_grid(  nb_wf,   resamples = cv_folds, grid = 2,   control = control_grid(verbose = TRUE))
best_nb <- select_best(nb_results, metric = "accuracy")
final_nb <- finalize_workflow(nb_wf, best_nb)
trained_nb <- fit(final_nb, data = train)
return(trained_nb)
}
get_preds_model <- function (model, target_column){
the_preds <-predict(model, new_data = test, type = "class")$.pred_class
return( the_preds)
}
# Fonction de test du modèle et calcul des métriques
test_model <- function(model, target_column) {
# Prédictions sur l'ensemble de test
the_preds <- predict(model, new_data = test)$.pred_class
# Convertir la variable cible en facteur et récupérer les prédictions
test[[target_column]] <- factor(test[[target_column]], levels = levels(the_preds))
# Calculer les métriques de performance
metrics <- metric_set(accuracy, precision, recall, f_meas)
# Créer un data frame avec les véritables valeurs et les prédictions
results_df <- tibble(
truth = test[[target_column]],
estimate = the_preds
)
# Calculer les métriques
the_metrics <- metrics(results_df, truth = truth, estimate = estimate)
return(the_metrics)
}
test_model_on_columns <- function(target_columns, used_model_funtcion){
# Appliquer les fonctions à toutes les variables cibles
results <- list()
preds <- list()
for (target_column in target_columns) {
# Entraîner le modèle pour chaque variable cible
trained_model <- used_model_funtcion(target_column)
preds[[target_column]] <- get_preds_model(trained_model ,target_column )
# Tester le modèle et récupérer les métriques
metrics <- test_model(trained_model, target_column)
# Ajouter les résultats au tableau
results[[target_column]] <- metrics
}
# Afficher les résultats
return(list(results = results, preds = preds))
}
# Utiliser la fonction avec un vecteur de colonnes cibles
resultats_et_predictions <- test_model_on_columns(target_columns,train_nb_model )
# Extraire les résultats et les prédictions
results <- resultats_et_predictions$results
preds <- resultats_et_predictions$preds
# Afficher les résultats et les prédictions
results
preds
# Charger les bibliothèques nécessaires
library(tidymodels)
library(data.table)
library(readxl)
# Charger les données
data <- read_excel("dataset_complet2.xlsx")
df <- as.data.table(data)
df <- df[complete.cases(df), ]
# Liste des variables d'intérêt
columns_of_interest <- c(
'ss2',  # Comportements préventifs
'sante','tb1',   # Anxiété de santé
'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Filtrer le dataframe pour ne garder que les colonnes d'intérêt
df_filtered <- df[, ..columns_of_interest]
# Split dataset (Train/Test)
df_split <- initial_split(df_filtered, prop = 0.8)
train <- training(df_split)
test <- testing(df_split)
# Liste des variables cibles # Performance scolaire
target_columns <- c('ss2',  # Comportements préventifs
'sante','tb1'   # Anxiété de santé
)
# Liste des variables explicatives
predictor_columns <- c(    'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Fonction d'entraînement du modèle
train_rf_model <- function(target_column) {
# Convertir les variables explicatives en numériques si nécessaire
train[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
test[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
# Convertir la variable cible en facteur dans l'ensemble d'entraînement et de test
train[[target_column]] <- as.factor(train[[target_column]])
test[[target_column]] <- as.factor(test[[target_column]])
# Assurez-vous que les niveaux dans l'ensemble de test sont les mêmes que ceux dans l'ensemble d'entraînement
test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
# Convertir la variable cible en facteur (car c'est une classification multiclasse)
train[[target_column]] <- as.factor(train[[target_column]])
# Créer la formule du modèle
formula <- as.formula(paste(target_column, "~", paste(predictor_columns, collapse = " + ")))
rf <- rand_forest(mtry = tune(), trees = 100) %>% set_engine("ranger") %>% set_mode("classification")
rf_wf <- workflow() %>% add_model(rf) %>% add_formula(formula)
cv_folds <- vfold_cv(train, v = 5, strata = target_column)
rf_results <- tune_grid(rf_wf, resamples = cv_folds, grid = 3, control = control_grid())
best_rf <- select_best(rf_results, metric = "accuracy")
final_rf <- finalize_workflow(rf_wf, best_rf)
trained_rf <- fit(final_rf, data = train)
return(trained_rf)
}
get_preds_model <- function (model, target_column){
the_preds <-predict(model, new_data = test, type = "class")$.pred_class
return( the_preds)
}
# Fonction de test du modèle et calcul des métriques
test_model <- function(model, target_column) {
# Prédictions sur l'ensemble de test
the_preds <- predict(model, new_data = test)$.pred_class
# Convertir la variable cible en facteur et récupérer les prédictions
test[[target_column]] <- factor(test[[target_column]], levels = levels(the_preds))
# Calculer les métriques de performance
metrics <- metric_set(accuracy, precision, recall, f_meas)
# Créer un data frame avec les véritables valeurs et les prédictions
results_df <- tibble(
truth = test[[target_column]],
estimate = the_preds
)
# Calculer les métriques
the_metrics <- metrics(results_df, truth = truth, estimate = estimate)
return(the_metrics)
}
test_model_on_columns <- function(target_columns, used_model_funtcion){
# Appliquer les fonctions à toutes les variables cibles
results <- list()
preds <- list()
for (target_column in target_columns) {
# Entraîner le modèle pour chaque variable cible
trained_model <- used_model_funtcion(target_column)
preds[[target_column]] <- get_preds_model(trained_model ,target_column )
# Tester le modèle et récupérer les métriques
metrics <- test_model(trained_model, target_column)
# Ajouter les résultats au tableau
results[[target_column]] <- metrics
}
# Afficher les résultats
return(list(results = results, preds = preds))
}
# Utiliser la fonction avec un vecteur de colonnes cibles
resultats_et_predictions <- test_model_on_columns(target_columns,train_rf_model )
# Extraire les résultats et les prédictions
results <- resultats_et_predictions$results
preds <- resultats_et_predictions$preds
# Afficher les résultats et les prédictions
results
preds
# Charger les bibliothèques nécessaires
library(tidymodels)
library(data.table)
library(readxl)
# Charger les données
data <- read_excel("dataset_complet2.xlsx")
df <- as.data.table(data)
df <- df[complete.cases(df), ]
# Liste des variables d'intérêt
columns_of_interest <- c(
'ss2',  # Comportements préventifs
'sante','tb1',   # Anxiété de santé
'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Filtrer le dataframe pour ne garder que les colonnes d'intérêt
df_filtered <- df[, ..columns_of_interest]
# Split dataset (Train/Test)
df_split <- initial_split(df_filtered, prop = 0.8)
train <- training(df_split)
test <- testing(df_split)
# Liste des variables cibles # Performance scolaire
target_columns <- c('ss2',  # Comportements préventifs
'sante','tb1'   # Anxiété de santé
)
# Liste des variables explicatives
predictor_columns <- c(    'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Convertir les variables explicatives en numériques si nécessaire
#train[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
#test[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
# Convertir la variable cible en facteur dans l'ensemble d'entraînement et de test
#train[[target_column]] <- as.factor(train[[target_column]])
#test[[target_column]] <- as.factor(test[[target_column]])
# Vérifier les niveaux dans l'ensemble d'entraînement et de test
#levels(train[[target_column]])
#levels(test[[target_column]])
# Assurez-vous que les niveaux dans l'ensemble de test sont les mêmes que ceux dans l'ensemble d'entraînement
#test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
#test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
# Vérifier les valeurs manquantes dans les variables explicatives et la cible
#anyNA(train[, ..predictor_columns])
#anyNA(train[[target_column]])
# Vérifier dans l'ensemble de test
#anyNA(test[, ..predictor_columns])
#anyNA(test[[target_column]])
# Exemple de conversion des variables en numérique
#train[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
# Vérifier si une colonne a une seule valeur unique
#constant_columns <- sapply(train, function(x) length(unique(x)) == 1)
#constant_columns
# Convertir la variable cible en facteur (car c'est une classification multiclasse)
#train[[target_column]] <- as.factor(train[[target_column]])
# Créer la formule du modèle
#formula <- as.formula(paste(target_column, "~", paste(predictor_columns, collapse = " + ")))
# Support Vector Machine pour classification multiclasse avec un noyau RBF
#svm_model <- svm_rbf(cost = tune()) %>%
# set_engine("kernlab") %>%
#set_mode("classification")
# Créer le workflow avec le modèle et la formule
#svm_wf <- workflow() %>%
# add_model(svm_model) %>%
#  add_formula(formula)
# Créer les folds pour la validation croisée
#cv_folds <- vfold_cv(train, v = 5, strata = target_column)
# Appliquer la grille de recherche avec le contrôle correct
#svm_results <- tune_grid(svm_wf, resamples = cv_folds, grid = 3, control = control_grid(verbose = TRUE))
#best_svm <- select_best(svm_results, metric = "accuracy")
#final_svm <- finalize_workflow(svm_wf, best_svm)
#trained_svm <- fit(final_svm, data = train)
# Afficher les résultats
#print(trained_svm)
#svm_preds <- predict(trained_svm, new_data = test)$.pred_class
#svm_preds
#test[[target_column]] <- factor(test[[target_column]], levels = levels(svm_preds))
# Calculer les métriques de performance
#metrics <- metric_set(accuracy, precision, recall, f_meas)
# Créer un data frame avec les véritables valeurs et les prédictions
#  results_df <- tibble(   truth = test[[target_column]],estimate = svm_preds)
# Calculer les métriques
#svm_metrics <- metrics(results_df, truth = truth, estimate = estimate)
#svm_metrics
# Fonction d'entraînement du modèle
train_svm_model <- function(target_column) {
# Convertir les variables explicatives en numériques si nécessaire
train[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
test[, (predictor_columns) := lapply(.SD, as.numeric), .SDcols = predictor_columns]
# Convertir la variable cible en facteur dans l'ensemble d'entraînement et de test
train[[target_column]] <- as.factor(train[[target_column]])
test[[target_column]] <- as.factor(test[[target_column]])
# Assurez-vous que les niveaux dans l'ensemble de test sont les mêmes que ceux dans l'ensemble d'entraînement
test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
test[[target_column]] <- factor(test[[target_column]], levels = levels(train[[target_column]]))
# Convertir la variable cible en facteur (car c'est une classification multiclasse)
train[[target_column]] <- as.factor(train[[target_column]])
# Créer la formule du modèle
formula <- as.formula(paste(target_column, "~", paste(predictor_columns, collapse = " + ")))
# Support Vector Machine pour classification multiclasse avec un noyau RBF
svm_model <- svm_rbf(cost = tune()) %>%
set_engine("kernlab") %>%
set_mode("classification")
# Créer le workflow avec le modèle et la formule
svm_wf <- workflow() %>%
add_model(svm_model) %>%
add_formula(formula)
# Créer les folds pour la validation croisée
cv_folds <- vfold_cv(train, v = 5, strata = target_column)
# Appliquer la grille de recherche avec le contrôle correct
svm_results <- tune_grid(svm_wf, resamples = cv_folds, grid = 3, control = control_grid(verbose = TRUE))
best_svm <- select_best(svm_results, metric = "accuracy")
final_svm <- finalize_workflow(svm_wf, best_svm)
trained_svm <- fit(final_svm, data = train)
return(trained_svm)
}
get_preds_model <- function (model, target_column){
the_preds <-predict(model, new_data = test, type = "class")$.pred_class
return( the_preds)
}
# Fonction de test du modèle et calcul des métriques
test_model <- function(model, target_column) {
# Prédictions sur l'ensemble de test
the_preds <- predict(model, new_data = test)$.pred_class
# Convertir la variable cible en facteur et récupérer les prédictions
test[[target_column]] <- factor(test[[target_column]], levels = levels(the_preds))
# Calculer les métriques de performance
metrics <- metric_set(accuracy, precision, recall, f_meas)
# Créer un data frame avec les véritables valeurs et les prédictions
results_df <- tibble(
truth = test[[target_column]],
estimate = the_preds
)
# Calculer les métriques
the_metrics <- metrics(results_df, truth = truth, estimate = estimate)
return(the_metrics)
}
test_model_on_columns <- function(target_columns, used_model_funtcion){
# Appliquer les fonctions à toutes les variables cibles
results <- list()
preds <- list()
for (target_column in target_columns) {
# Entraîner le modèle pour chaque variable cible
trained_model <- used_model_funtcion(target_column)
preds[[target_column]] <- get_preds_model(trained_model ,target_column )
# Tester le modèle et récupérer les métriques
metrics <- test_model(trained_model, target_column)
# Ajouter les résultats au tableau
results[[target_column]] <- metrics
}
# Afficher les résultats
return(list(results = results, preds = preds))
}
# Utiliser la fonction avec un vecteur de colonnes cibles
resultats_et_predictions <- test_model_on_columns(target_columns,train_svm_model )
# Charger les bibliothèques nécessaires
library(tidymodels)
library(data.table)
library(readxl)
# Charger les données
data <- read_excel("dataset_complet1.xlsx")
df <- as.data.table(data)
# Liste des variables d'intérêt pour l'impact de la perception des risques et comportements de santé
columns_of_interest <- c(
'ss4',  'ss2',  # Comportements préventifs
'sante','tb1',   # Anxiété de santé
'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
columns_to_filter <- c(
'ss2',  'pr1a'	,'pr1b'	,'pr1c',	'pr1d','pr1e','pr1f','pr1g',	'pr1h', 'pr2a', 	'pr2b'	,'pr2c'	,'pr2d'	, 'pr2e'	,'pr2f'	,'pr2g',	'pr2h',  # Perception des risques environnementaux
'alimentation_saine','ptit_dej_semaine','ptit_dej_weekend','al4_1', 'al4_3', 'jour_sport','sport_extra', 'sd1',  # Comportements de santé
'ao1', 'ao2a', 'cn1',  # Consommation de substances
'niveau_scol', 'type_ecole', 'vf2_1',	'vf2_2'	,'vf2_3',	'vf2_4',	'vf2_5',	'vf2_6'	,'vf2_7',
'sexe', 'age'  # Caractéristiques sociodémographiques
)
# Filtrer le dataframe pour ne garder que les colonnes d'intérêt
df_filtered <- df[, ..columns_of_interest]
## Voir les valeurs dans chacune des colonnes
# Afficher les valeurs uniques pour chaque colonne dans columns_of_interest
unique_values <- lapply(columns_of_interest, function(col) unique(df_filtered[[col]]))
# Afficher les résultats
names(unique_values) <- columns_of_interest
unique_values
# Remplacer les valeurs manquantes (NA) par 0 dans toutes les colonnes de columns_of_interest
df_filtered[, (columns_to_filter) := lapply(.SD, function(x) replace(x, is.na(x), 0)), .SDcols = columns_to_filter]
# Supprimer les lignes avec des valeurs manquantes dans les colonnes d'intérêt restantes
df_filtered <- df_filtered[complete.cases(df_filtered), ]
# Vérifier que les valeurs manquantes ont été remplacées
sapply(df_filtered[, ..columns_of_interest], function(x) sum(is.na(x)))  # Compter les valeurs NA restantes
# Sauvegarder les données filtrées dans un nouveau fichier Excel
library(writexl)
write_xlsx(df_filtered, "dataset_complet2_ss4.xlsx")
